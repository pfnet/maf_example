import maf
import maflib
import util

VERSION = '0.0.0'
APPNAME = 'pydata_demo'

def options(opt):
    opt.load('maf')

def configure(conf):
    conf.load('maf')

def build(bld):
    CAFFE_ROOT = '<path/to/caffe/root/dir>' # Fill in the path according to your environment
    TRAIN_DATA = '%s/examples/cifar10/cifar10_train_leveldb' % CAFFE_ROOT
    DEV_DATA = '%s/examples/cifar10/cifar10_test_leveldb' % CAFFE_ROOT
    MEAN_FILE = '%s/examples/cifar10/mean.binaryproto' % CAFFE_ROOT
    IMAGE_FILE = 'data/cifar-10-batches-py/data_batch_1'

    bld(source = 'template/data.prototxt.base',
        target = 'prototxt/part/data.prototxt',
        rule = util.prototxt.generate_datalayer,
        parameters = maflib.util.product({'train_data' : [TRAIN_DATA],
                                          'dev_data' : [DEV_DATA],
                                          'mean_file' : [MEAN_FILE]}))

    bld(source = 'template/net.prototxt.base',
        target = 'prototxt/part/net.prototxt',
        rule = util.prototxt.generate_net,
        parameters = maflib.util.sample(10, {'conv_num_output_1' : [32, 64], 'conv_num_output_2' : [32, 64], 'conv_num_output_3' : [32, 64],
                                             'conv_kernel_size_1' : [3, 5], 'conv_kernel_size_2' : [3, 5], 'conv_kernel_size_3' : [3, 5],
                                             'pool_1' : ['MAX', 'AVE'], 'pool_2' : ['MAX', 'AVE'], 'pool_3' : ['MAX', 'AVE'],
                                             'pool_kernel_size_1' : [3, 5], 'pool_kernel_size_2' : [3, 5], 'pool_kernel_size_3' : [3, 5]}))

    bld(source = 'prototxt/part/data.prototxt prototxt/part/net.prototxt template/loss.prototxt',
        target = 'prototxt/part/train.prototxt',
        rule = 'cat ${SRC} > ${TGT}')

    bld(source = 'template/solver.prototxt.base prototxt/part/train.prototxt',
        target = 'prototxt/solver.prototxt snapshot/train',
        rule = util.prototxt.generate_solver,
        parameters = maflib.util.product({'base_lr' : [0.001, 0.1, 0.1], 'momentum' : [0.7, 0.9], 'weight_decay' : [0.001, 0.01],
					  'test_iter' : [100], 'test_interval' : [1000],
                                          'lr_policy' : ['inv'], 'gamma': [0.0001], 'power': [0.75],
                                          'display' : [32], 'max_iter' : [10000], 'snapshot' : [2000], 'solver_mode' : ['GPU']}))

    bld(source = 'template/blob.prototxt prototxt/part/net.prototxt template/softmax.prototxt',
        target = 'prototxt/dev.prototxt',
        rule = 'cat ${SRC} > ${TGT}')
    bld(source = 'prototxt/solver.prototxt',
        target = 'log/train.log',
        rule = 'caffe train --solver=${SRC} > ${TGT} 2>&1')
    bld(source = 'log/train.log',
        target = 'result/loss.json',
        rule = util.log.extract_loss)
    bld(source = 'result/loss.json',
        target = 'result/loss.png',
        rule = util.plot.plot,
        aggregate_by = 'base_lr momentum weight_decay')
    bld(source = 'prototxt/dev.prototxt snapshot/train log/train.log',
        target = 'result/feature.png',
        rule = util.classify.classify(image_file = IMAGE_FILE))
